{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6938815,"sourceType":"datasetVersion","datasetId":3984786}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os \nimport pandas as pd \nimport numpy as np \nimport cv2\n\nimport torch \nimport torch.nn as nn\nimport torch.optim as optim \nimport torchvision\nimport albumentations as A\n\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, random_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-15T10:23:33.325561Z","iopub.execute_input":"2023-11-15T10:23:33.326231Z","iopub.status.idle":"2023-11-15T10:23:38.650549Z","shell.execute_reply.started":"2023-11-15T10:23:33.326196Z","shell.execute_reply":"2023-11-15T10:23:38.649466Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"%pip install -q segmentation-models-pytorch","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:23:38.652514Z","iopub.execute_input":"2023-11-15T10:23:38.653602Z","iopub.status.idle":"2023-11-15T10:23:57.871061Z","shell.execute_reply.started":"2023-11-15T10:23:38.653572Z","shell.execute_reply":"2023-11-15T10:23:57.869786Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"batch_size = 4\nlr = 1e-4\nnum_epochs = 50\ndevice = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\ncriterion = nn.CrossEntropyLoss()\nbest_val_loss = 9999999\ndisplay_step = 50","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:23:57.872758Z","iopub.execute_input":"2023-11-15T10:23:57.873178Z","iopub.status.idle":"2023-11-15T10:23:57.904511Z","shell.execute_reply.started":"2023-11-15T10:23:57.873127Z","shell.execute_reply":"2023-11-15T10:23:57.903740Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class NeolypsDataset(Dataset):\n    def __init__(self, img_list, mask_list, transform = None):\n        self.img_list = img_list\n        self.mask_list = mask_list\n        self.transform = transform\n        \n        print(f'Len of images: {len(self.img_list)}')\n        print(f'Len of masks: {len(self.mask_list)}')\n    \n    def __len__(self):\n        return len(self.img_list)\n    \n    def _read_mask(self, mask_path): \n        mask = cv2.imread(mask_path)\n        \n        # Convert to HSV\n        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2HSV)\n        \n        # Follow StackOverFlow: Red (0->10 and 160->179)\n        lower1 = np.array([0, 100, 20])\n        upper1 = np.array([10, 255, 255])\n        \n        lower2 = np.array([160, 100, 20])\n        upper2 = np.array([179, 255, 255])\n        \n        # Follow StackOverFlow: Green (36 -> 70)\n        lower_g = np.array([35,25,25])\n        upper_g = np.array([70,255,255])\n        \n        red_mask = cv2.inRange(mask, lower1, upper1) + cv2.inRange(mask, lower2, upper2)\n        green_mask = cv2.inRange(mask, lower_g, upper_g)\n        \n        red_mask[red_mask != 0] = 1 # Neopolyp pixel = 1\n        green_mask[green_mask != 0] = 2 # Non neo polyp pixel = 2, background is 0\n        \n        full_mask = cv2.bitwise_or(red_mask, green_mask)\n        full_mask = full_mask.astype(np.int8)\n        \n        return full_mask\n    \n    def __getitem__(self, idx):\n        img_path = self.img_list[idx]\n        mask_path = self.mask_list[idx]\n        \n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        mask = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        mask = self._read_mask(mask_path)\n        \n        if self.transform:\n            transformer = self.transform(image=img, mask=mask)\n            img = transformer['image'].float()\n            mask = transformer['mask'].float()\n        \n        return img, mask","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:23:57.906582Z","iopub.execute_input":"2023-11-15T10:23:57.906881Z","iopub.status.idle":"2023-11-15T10:23:57.929178Z","shell.execute_reply.started":"2023-11-15T10:23:57.906857Z","shell.execute_reply":"2023-11-15T10:23:57.928393Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Create the dataset","metadata":{}},{"cell_type":"code","source":"img_dir = '/kaggle/input/bkai-igh-neopolyp/train/train'\nmask_dir = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\n\nimg_list = [\n    os.path.join(img_dir, x) for x in os.listdir(img_dir)\n]\nmask_list = [\n    os.path.join(mask_dir, x) for x in os.listdir(mask_dir)\n]","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:23:57.930249Z","iopub.execute_input":"2023-11-15T10:23:57.930529Z","iopub.status.idle":"2023-11-15T10:23:58.332192Z","shell.execute_reply.started":"2023-11-15T10:23:57.930506Z","shell.execute_reply":"2023-11-15T10:23:58.331326Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Create the transform","metadata":{}},{"cell_type":"code","source":"train_transform = A.Compose(\n    [\n        A.Resize(256, 256, interpolation=cv2.INTER_LINEAR),\n        A.VerticalFlip(p=0.3),\n        A.HorizontalFlip(p=0.3),\n        A.RGBShift(p=0.3),\n        A.Normalize(),\n        ToTensorV2()\n    ]\n)\n\nval_transform = A.Compose(\n    [\n        A.Resize(256, 256, interpolation=cv2.INTER_LINEAR),\n        A.Normalize(),\n        ToTensorV2()\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:23:58.333286Z","iopub.execute_input":"2023-11-15T10:23:58.333574Z","iopub.status.idle":"2023-11-15T10:23:58.340451Z","shell.execute_reply.started":"2023-11-15T10:23:58.333550Z","shell.execute_reply":"2023-11-15T10:23:58.339502Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Train test split with ratio 0.8","metadata":{}},{"cell_type":"code","source":"train_size = int(0.9 * len(img_list))\n\ntrain_dataset = NeolypsDataset(img_list[:train_size], mask_list[:train_size], transform=train_transform)\nval_dataset = NeolypsDataset(img_list[train_size:], mask_list[train_size:], transform=val_transform)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:23:58.341786Z","iopub.execute_input":"2023-11-15T10:23:58.342140Z","iopub.status.idle":"2023-11-15T10:23:58.352829Z","shell.execute_reply.started":"2023-11-15T10:23:58.342114Z","shell.execute_reply":"2023-11-15T10:23:58.351916Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Len of images: 900\nLen of masks: 900\nLen of images: 100\nLen of masks: 100\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Create the dataloader","metadata":{}},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:23:58.353998Z","iopub.execute_input":"2023-11-15T10:23:58.354247Z","iopub.status.idle":"2023-11-15T10:23:58.363930Z","shell.execute_reply.started":"2023-11-15T10:23:58.354226Z","shell.execute_reply":"2023-11-15T10:23:58.363064Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Training Phase","metadata":{}},{"cell_type":"markdown","source":"Model","metadata":{}},{"cell_type":"code","source":"import segmentation_models_pytorch as smp\n\nmodel = smp.UnetPlusPlus(\n    encoder_name=\"resnet50\",        \n    encoder_weights=\"imagenet\",     \n    in_channels=3,                  \n    classes=3     \n)\n\nmodel = model.to(device)\noptimizer = optim.Adam(model.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:23:58.364997Z","iopub.execute_input":"2023-11-15T10:23:58.365282Z","iopub.status.idle":"2023-11-15T10:24:05.931547Z","shell.execute_reply.started":"2023-11-15T10:23:58.365258Z","shell.execute_reply":"2023-11-15T10:24:05.930768Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n100%|██████████| 97.8M/97.8M [00:01<00:00, 99.9MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\n\nwandb.login(key=\"8b9a21f3b6f5fbf21131e5a7c7d5bf22a2ad5f0c\")\n\nwandb.init(project=\"DL-Assignment\", name=f'df-{num_epochs}-{batch_size}-{lr}')\n\n# Training loop\ntrain_loss = 0\nbest_val_loss = float('inf')\n\nfor epoch in range(num_epochs):\n    model.train()\n    \n    for i, (img, label) in enumerate(train_dataloader):\n        img = img.to(device)\n        label = label.to(device)\n        \n        # Forward \n        label = label.squeeze(dim=1).long()\n        outputs = model(img)\n        \n        # Loss \n        loss = criterion(outputs, label)\n        \n        # Backward\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n        train_loss += loss.item()\n        \n        if (i + 1) % display_step == 0:\n            avg_train_loss = train_loss / display_step\n            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_dataloader)}], Train Loss: {avg_train_loss:.10f}\")\n            wandb.log({\"Train loss\": avg_train_loss})\n            train_loss = 0\n    \n    model.eval()\n    \n    with torch.no_grad():\n        val_loss = 0\n        \n        for img, label in val_dataloader:\n            img = img.to(device)\n            label = label.to(device)\n            \n            label = label.squeeze(dim=1).long()\n            outputs = model(img)\n            \n            val_loss += criterion(outputs.float(), label.long()).item()\n    \n    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss/len(val_dataloader):.10f}\")\n    \n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        checkpoint = {\n            'epoch': epoch,\n            'model': model.state_dict(),\n            'optimizer': optimizer.state_dict(),\n            'loss': val_loss,\n        }\n        torch.save(checkpoint, 'model.pth')\n    \n    wandb.log({\"Valid loss\": val_loss})","metadata":{"execution":{"iopub.status.busy":"2023-11-15T10:24:05.934464Z","iopub.execute_input":"2023-11-15T10:24:05.935144Z","iopub.status.idle":"2023-11-15T11:11:50.383068Z","shell.execute_reply.started":"2023-11-15T10:24:05.935109Z","shell.execute_reply":"2023-11-15T11:11:50.381433Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhokage321xxx\u001b[0m (\u001b[33mteam-thay-linh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.12"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231115_102409-kin7kiso</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/team-thay-linh/DL-Assignment/runs/kin7kiso' target=\"_blank\">df-50-4-0.0001</a></strong> to <a href='https://wandb.ai/team-thay-linh/DL-Assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/team-thay-linh/DL-Assignment' target=\"_blank\">https://wandb.ai/team-thay-linh/DL-Assignment</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/team-thay-linh/DL-Assignment/runs/kin7kiso' target=\"_blank\">https://wandb.ai/team-thay-linh/DL-Assignment/runs/kin7kiso</a>"},"metadata":{}},{"name":"stdout","text":"Epoch [1/50], Step [50/225], Train Loss: 1.1102343285\nEpoch [1/50], Step [100/225], Train Loss: 0.6358348346\nEpoch [1/50], Step [150/225], Train Loss: 0.4482467830\nEpoch [1/50], Step [200/225], Train Loss: 0.3414552289\nEpoch [1/50], Validation Loss: 0.2545958686\nEpoch [2/50], Step [50/225], Train Loss: 0.3674542990\nEpoch [2/50], Step [100/225], Train Loss: 0.1970529032\nEpoch [2/50], Step [150/225], Train Loss: 0.1629444543\nEpoch [2/50], Step [200/225], Train Loss: 0.1506556755\nEpoch [2/50], Validation Loss: 0.1305352184\nEpoch [3/50], Step [50/225], Train Loss: 0.1757016560\nEpoch [3/50], Step [100/225], Train Loss: 0.1034808590\nEpoch [3/50], Step [150/225], Train Loss: 0.0954039585\nEpoch [3/50], Step [200/225], Train Loss: 0.0790156654\nEpoch [3/50], Validation Loss: 0.0830792765\nEpoch [4/50], Step [50/225], Train Loss: 0.1191307406\nEpoch [4/50], Step [100/225], Train Loss: 0.0737433868\nEpoch [4/50], Step [150/225], Train Loss: 0.0769483120\nEpoch [4/50], Step [200/225], Train Loss: 0.0699801324\nEpoch [4/50], Validation Loss: 0.0767934202\nEpoch [5/50], Step [50/225], Train Loss: 0.1062771897\nEpoch [5/50], Step [100/225], Train Loss: 0.0610201942\nEpoch [5/50], Step [150/225], Train Loss: 0.0585735185\nEpoch [5/50], Step [200/225], Train Loss: 0.0616908098\nEpoch [5/50], Validation Loss: 0.0634585588\nEpoch [6/50], Step [50/225], Train Loss: 0.0860577105\nEpoch [6/50], Step [100/225], Train Loss: 0.0533314776\nEpoch [6/50], Step [150/225], Train Loss: 0.0456113631\nEpoch [6/50], Step [200/225], Train Loss: 0.0555868458\nEpoch [6/50], Validation Loss: 0.0602891851\nEpoch [7/50], Step [50/225], Train Loss: 0.0817142921\nEpoch [7/50], Step [100/225], Train Loss: 0.0356164450\nEpoch [7/50], Step [150/225], Train Loss: 0.0468687260\nEpoch [7/50], Step [200/225], Train Loss: 0.0403747716\nEpoch [7/50], Validation Loss: 0.0592532465\nEpoch [8/50], Step [50/225], Train Loss: 0.0593964644\nEpoch [8/50], Step [100/225], Train Loss: 0.0420959477\nEpoch [8/50], Step [150/225], Train Loss: 0.0366829034\nEpoch [8/50], Step [200/225], Train Loss: 0.0403165741\nEpoch [8/50], Validation Loss: 0.0585402916\nEpoch [9/50], Step [50/225], Train Loss: 0.0600056116\nEpoch [9/50], Step [100/225], Train Loss: 0.0324483825\nEpoch [9/50], Step [150/225], Train Loss: 0.0398007592\nEpoch [9/50], Step [200/225], Train Loss: 0.0352886296\nEpoch [9/50], Validation Loss: 0.0563361395\nEpoch [10/50], Step [50/225], Train Loss: 0.0658331116\nEpoch [10/50], Step [100/225], Train Loss: 0.0436920160\nEpoch [10/50], Step [150/225], Train Loss: 0.0287402981\nEpoch [10/50], Step [200/225], Train Loss: 0.0266989851\nEpoch [10/50], Validation Loss: 0.0578461752\nEpoch [11/50], Step [50/225], Train Loss: 0.0428455331\nEpoch [11/50], Step [100/225], Train Loss: 0.0358786857\nEpoch [11/50], Step [150/225], Train Loss: 0.0280600256\nEpoch [11/50], Step [200/225], Train Loss: 0.0376468670\nEpoch [11/50], Validation Loss: 0.0561646514\nEpoch [12/50], Step [50/225], Train Loss: 0.0475601927\nEpoch [12/50], Step [100/225], Train Loss: 0.0365205958\nEpoch [12/50], Step [150/225], Train Loss: 0.0223975589\nEpoch [12/50], Step [200/225], Train Loss: 0.0299457226\nEpoch [12/50], Validation Loss: 0.0596181812\nEpoch [13/50], Step [50/225], Train Loss: 0.0393805962\nEpoch [13/50], Step [100/225], Train Loss: 0.0300340246\nEpoch [13/50], Step [150/225], Train Loss: 0.0303887664\nEpoch [13/50], Step [200/225], Train Loss: 0.0369158091\nEpoch [13/50], Validation Loss: 0.0560001172\nEpoch [14/50], Step [50/225], Train Loss: 0.0525454321\nEpoch [14/50], Step [100/225], Train Loss: 0.0213577825\nEpoch [14/50], Step [150/225], Train Loss: 0.0250142941\nEpoch [14/50], Step [200/225], Train Loss: 0.0296135864\nEpoch [14/50], Validation Loss: 0.0573207276\nEpoch [15/50], Step [50/225], Train Loss: 0.0537922524\nEpoch [15/50], Step [100/225], Train Loss: 0.0270722280\nEpoch [15/50], Step [150/225], Train Loss: 0.0466250038\nEpoch [15/50], Step [200/225], Train Loss: 0.0278143265\nEpoch [15/50], Validation Loss: 0.0469446838\nEpoch [16/50], Step [50/225], Train Loss: 0.0454176516\nEpoch [16/50], Step [100/225], Train Loss: 0.0241757181\nEpoch [16/50], Step [150/225], Train Loss: 0.0239503438\nEpoch [16/50], Step [200/225], Train Loss: 0.0254089401\nEpoch [16/50], Validation Loss: 0.0500211795\nEpoch [17/50], Step [50/225], Train Loss: 0.0296009692\nEpoch [17/50], Step [100/225], Train Loss: 0.0192155768\nEpoch [17/50], Step [150/225], Train Loss: 0.0235223572\nEpoch [17/50], Step [200/225], Train Loss: 0.0380010079\nEpoch [17/50], Validation Loss: 0.0537776053\nEpoch [18/50], Step [50/225], Train Loss: 0.0342172256\nEpoch [18/50], Step [100/225], Train Loss: 0.0192475971\nEpoch [18/50], Step [150/225], Train Loss: 0.0292913216\nEpoch [18/50], Step [200/225], Train Loss: 0.0181848437\nEpoch [18/50], Validation Loss: 0.0539146507\nEpoch [19/50], Step [50/225], Train Loss: 0.0351211469\nEpoch [19/50], Step [100/225], Train Loss: 0.0184190158\nEpoch [19/50], Step [150/225], Train Loss: 0.0184302871\nEpoch [19/50], Step [200/225], Train Loss: 0.0202616248\nEpoch [19/50], Validation Loss: 0.0537102225\nEpoch [20/50], Step [50/225], Train Loss: 0.0339716085\nEpoch [20/50], Step [100/225], Train Loss: 0.0439359577\nEpoch [20/50], Step [150/225], Train Loss: 0.0219656226\nEpoch [20/50], Step [200/225], Train Loss: 0.0232259464\nEpoch [20/50], Validation Loss: 0.0487224036\nEpoch [21/50], Step [50/225], Train Loss: 0.0330144054\nEpoch [21/50], Step [100/225], Train Loss: 0.0172723783\nEpoch [21/50], Step [150/225], Train Loss: 0.0229741929\nEpoch [21/50], Step [200/225], Train Loss: 0.0290039928\nEpoch [21/50], Validation Loss: 0.0526194938\nEpoch [22/50], Step [50/225], Train Loss: 0.0258300025\nEpoch [22/50], Step [100/225], Train Loss: 0.0135106410\nEpoch [22/50], Step [150/225], Train Loss: 0.0290751238\nEpoch [22/50], Step [200/225], Train Loss: 0.0191870331\nEpoch [22/50], Validation Loss: 0.0678198117\nEpoch [23/50], Step [50/225], Train Loss: 0.0412691744\nEpoch [23/50], Step [100/225], Train Loss: 0.0180436717\nEpoch [23/50], Step [150/225], Train Loss: 0.0140874359\nEpoch [23/50], Step [200/225], Train Loss: 0.0197218691\nEpoch [23/50], Validation Loss: 0.0516570785\nEpoch [24/50], Step [50/225], Train Loss: 0.0343936087\nEpoch [24/50], Step [100/225], Train Loss: 0.0178259320\nEpoch [24/50], Step [150/225], Train Loss: 0.0230232982\nEpoch [24/50], Step [200/225], Train Loss: 0.0205674336\nEpoch [24/50], Validation Loss: 0.0570043354\nEpoch [25/50], Step [50/225], Train Loss: 0.0443286324\nEpoch [25/50], Step [100/225], Train Loss: 0.0289026604\nEpoch [25/50], Step [150/225], Train Loss: 0.0221465866\nEpoch [25/50], Step [200/225], Train Loss: 0.0311630111\nEpoch [25/50], Validation Loss: 0.0527296496\nEpoch [26/50], Step [50/225], Train Loss: 0.0310153732\nEpoch [26/50], Step [100/225], Train Loss: 0.0188971533\nEpoch [26/50], Step [150/225], Train Loss: 0.0193976314\nEpoch [26/50], Step [200/225], Train Loss: 0.0218697373\nEpoch [26/50], Validation Loss: 0.0618590104\nEpoch [27/50], Step [50/225], Train Loss: 0.0350673043\nEpoch [27/50], Step [100/225], Train Loss: 0.0147463348\nEpoch [27/50], Step [150/225], Train Loss: 0.0148000894\nEpoch [27/50], Step [200/225], Train Loss: 0.0245914144\nEpoch [27/50], Validation Loss: 0.0633800074\nEpoch [28/50], Step [50/225], Train Loss: 0.0257548267\nEpoch [28/50], Step [100/225], Train Loss: 0.0132397449\nEpoch [28/50], Step [150/225], Train Loss: 0.0139239265\nEpoch [28/50], Step [200/225], Train Loss: 0.0173713127\nEpoch [28/50], Validation Loss: 0.0500615644\nEpoch [29/50], Step [50/225], Train Loss: 0.0251539427\nEpoch [29/50], Step [100/225], Train Loss: 0.0124965034\nEpoch [29/50], Step [150/225], Train Loss: 0.0123245261\nEpoch [29/50], Step [200/225], Train Loss: 0.0157341882\nEpoch [29/50], Validation Loss: 0.0605242603\nEpoch [30/50], Step [50/225], Train Loss: 0.0231699075\nEpoch [30/50], Step [100/225], Train Loss: 0.0132869884\nEpoch [30/50], Step [150/225], Train Loss: 0.0157589526\nEpoch [30/50], Step [200/225], Train Loss: 0.0219540652\nEpoch [30/50], Validation Loss: 0.0779095087\nEpoch [31/50], Step [50/225], Train Loss: 0.0430892256\nEpoch [31/50], Step [100/225], Train Loss: 0.0152430759\nEpoch [31/50], Step [150/225], Train Loss: 0.0178858855\nEpoch [31/50], Step [200/225], Train Loss: 0.0200437878\nEpoch [31/50], Validation Loss: 0.0716549964\nEpoch [32/50], Step [50/225], Train Loss: 0.0207933372\nEpoch [32/50], Step [100/225], Train Loss: 0.0118418735\nEpoch [32/50], Step [150/225], Train Loss: 0.0194116723\nEpoch [32/50], Step [200/225], Train Loss: 0.0135183742\nEpoch [32/50], Validation Loss: 0.0617960603\nEpoch [33/50], Step [50/225], Train Loss: 0.0208694803\nEpoch [33/50], Step [100/225], Train Loss: 0.0152078158\nEpoch [33/50], Step [150/225], Train Loss: 0.0099415443\nEpoch [33/50], Step [200/225], Train Loss: 0.0087503178\nEpoch [33/50], Validation Loss: 0.0521576643\nEpoch [34/50], Step [50/225], Train Loss: 0.0168723645\nEpoch [34/50], Step [100/225], Train Loss: 0.0118564790\nEpoch [34/50], Step [150/225], Train Loss: 0.0196027963\nEpoch [34/50], Step [200/225], Train Loss: 0.0272565443\nEpoch [34/50], Validation Loss: 0.0590668111\nEpoch [35/50], Step [50/225], Train Loss: 0.0396868205\nEpoch [35/50], Step [100/225], Train Loss: 0.0138875270\nEpoch [35/50], Step [150/225], Train Loss: 0.0134885714\nEpoch [35/50], Step [200/225], Train Loss: 0.0176823405\nEpoch [35/50], Validation Loss: 0.0644109300\nEpoch [36/50], Step [50/225], Train Loss: 0.0190192960\nEpoch [36/50], Step [100/225], Train Loss: 0.0102483205\nEpoch [36/50], Step [150/225], Train Loss: 0.0222156583\nEpoch [36/50], Step [200/225], Train Loss: 0.0169520050\nEpoch [36/50], Validation Loss: 0.0604213119\nEpoch [37/50], Step [50/225], Train Loss: 0.0166612196\nEpoch [37/50], Step [100/225], Train Loss: 0.0132919772\nEpoch [37/50], Step [150/225], Train Loss: 0.0112664965\nEpoch [37/50], Step [200/225], Train Loss: 0.0101881333\nEpoch [37/50], Validation Loss: 0.0660930029\nEpoch [38/50], Step [50/225], Train Loss: 0.0187115517\nEpoch [38/50], Step [100/225], Train Loss: 0.0084762484\nEpoch [38/50], Step [150/225], Train Loss: 0.0105171983\nEpoch [38/50], Step [200/225], Train Loss: 0.0159379915\nEpoch [38/50], Validation Loss: 0.0755850087\nEpoch [39/50], Step [50/225], Train Loss: 0.0257480442\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     12\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (img, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m     15\u001b[0m         img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     16\u001b[0m         label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[4], line 49\u001b[0m, in \u001b[0;36mNeolypsDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     46\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m     47\u001b[0m mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m---> 49\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     52\u001b[0m     transformer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image\u001b[38;5;241m=\u001b[39mimg, mask\u001b[38;5;241m=\u001b[39mmask)\n","Cell \u001b[0;32mIn[4], line 31\u001b[0m, in \u001b[0;36mNeolypsDataset._read_mask\u001b[0;34m(self, mask_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m upper_g \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m70\u001b[39m,\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m255\u001b[39m])\n\u001b[1;32m     30\u001b[0m red_mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39minRange(mask, lower1, upper1) \u001b[38;5;241m+\u001b[39m cv2\u001b[38;5;241m.\u001b[39minRange(mask, lower2, upper2)\n\u001b[0;32m---> 31\u001b[0m green_mask \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minRange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper_g\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m red_mask[red_mask \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# Neopolyp pixel = 1\u001b[39;00m\n\u001b[1;32m     34\u001b[0m green_mask[green_mask \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m# Non neo polyp pixel = 2, background is 0\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}