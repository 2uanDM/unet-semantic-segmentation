{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-15T14:33:40.738527Z","iopub.status.busy":"2023-11-15T14:33:40.738118Z","iopub.status.idle":"2023-11-15T14:33:46.896249Z","shell.execute_reply":"2023-11-15T14:33:46.895137Z","shell.execute_reply.started":"2023-11-15T14:33:40.738491Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import os \n","import pandas as pd \n","import numpy as np \n","import cv2\n","\n","import torch \n","import torch.nn as nn\n","import torch.optim as optim \n","import torchvision\n","import albumentations as A\n","\n","from albumentations.pytorch.transforms import ToTensorV2\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader, random_split"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T14:33:46.898799Z","iopub.status.busy":"2023-11-15T14:33:46.898289Z","iopub.status.idle":"2023-11-15T14:34:08.657727Z","shell.execute_reply":"2023-11-15T14:34:08.656277Z","shell.execute_reply.started":"2023-11-15T14:33:46.898768Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install -q segmentation-models-pytorch"]},{"cell_type":"markdown","metadata":{},"source":["# Config"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T14:34:08.659863Z","iopub.status.busy":"2023-11-15T14:34:08.659447Z","iopub.status.idle":"2023-11-15T14:34:08.694445Z","shell.execute_reply":"2023-11-15T14:34:08.693287Z","shell.execute_reply.started":"2023-11-15T14:34:08.659827Z"},"trusted":true},"outputs":[],"source":["batch_size = 4\n","lr = 1e-4\n","num_epochs = 25\n","device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n","criterion = nn.CrossEntropyLoss()\n","best_val_loss = 9999999\n","display_step = 50"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T14:34:08.698155Z","iopub.status.busy":"2023-11-15T14:34:08.697838Z","iopub.status.idle":"2023-11-15T14:34:08.721457Z","shell.execute_reply":"2023-11-15T14:34:08.720444Z","shell.execute_reply.started":"2023-11-15T14:34:08.698129Z"},"trusted":true},"outputs":[],"source":["class NeolypsDataset(Dataset):\n","    def __init__(self, img_list, mask_list, transform = None):\n","        self.img_list = img_list\n","        self.mask_list = mask_list\n","        self.transform = transform\n","        \n","        print(f'Len of images: {len(self.img_list)}')\n","        print(f'Len of masks: {len(self.mask_list)}')\n","    \n","    def __len__(self):\n","        return len(self.img_list)\n","    \n","    def _read_mask(self, mask_path): \n","        mask = cv2.imread(mask_path)\n","        \n","        # Convert to HSV\n","        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2HSV)\n","        \n","        # Follow StackOverFlow: Red (0->10 and 160->179)\n","        lower1 = np.array([0, 100, 20])\n","        upper1 = np.array([10, 255, 255])\n","        \n","        lower2 = np.array([160, 100, 20])\n","        upper2 = np.array([179, 255, 255])\n","        \n","        # Follow StackOverFlow: Green (36 -> 70)\n","        lower_g = np.array([35,25,25])\n","        upper_g = np.array([70,255,255])\n","        \n","        red_mask = cv2.inRange(mask, lower1, upper1) + cv2.inRange(mask, lower2, upper2)\n","        green_mask = cv2.inRange(mask, lower_g, upper_g)\n","        \n","        red_mask[red_mask != 0] = 1 # Neopolyp pixel = 1\n","        green_mask[green_mask != 0] = 2 # Non neo polyp pixel = 2, background is 0\n","        \n","        full_mask = cv2.bitwise_or(red_mask, green_mask)\n","        full_mask = full_mask.astype(np.int8)\n","        \n","        return full_mask\n","    \n","    def __getitem__(self, idx):\n","        img_path = self.img_list[idx]\n","        mask_path = self.mask_list[idx]\n","        \n","        img = cv2.imread(img_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        mask = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        \n","        mask = self._read_mask(mask_path)\n","        \n","        if self.transform:\n","            transformer = self.transform(image=img, mask=mask)\n","            img = transformer['image'].float()\n","            mask = transformer['mask'].float()\n","        \n","        return img, mask"]},{"cell_type":"markdown","metadata":{},"source":["Create the dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T14:34:08.723081Z","iopub.status.busy":"2023-11-15T14:34:08.722699Z","iopub.status.idle":"2023-11-15T14:34:09.114183Z","shell.execute_reply":"2023-11-15T14:34:09.113124Z","shell.execute_reply.started":"2023-11-15T14:34:08.723052Z"},"trusted":true},"outputs":[],"source":["img_dir = '/kaggle/input/bkai-igh-neopolyp/train/train'\n","mask_dir = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\n","\n","img_list = [\n","    os.path.join(img_dir, x) for x in os.listdir(img_dir)\n","]\n","mask_list = [\n","    os.path.join(mask_dir, x) for x in os.listdir(mask_dir)\n","]"]},{"cell_type":"markdown","metadata":{},"source":["Create the transform"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T14:34:09.115903Z","iopub.status.busy":"2023-11-15T14:34:09.115572Z","iopub.status.idle":"2023-11-15T14:34:09.128280Z","shell.execute_reply":"2023-11-15T14:34:09.127144Z","shell.execute_reply.started":"2023-11-15T14:34:09.115875Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/blur/transforms.py:184: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n","  warnings.warn(\n"]}],"source":["train_transform = A.Compose(\n","    [\n","        A.Resize(256, 256, interpolation=cv2.INTER_LINEAR),\n","        A.VerticalFlip(p=0.3),\n","        A.HorizontalFlip(p=0.3),\n","        A.RGBShift(p=0.3),\n","        A.RandomBrightnessContrast(p=0.3),\n","        A.GaussNoise(p=0.3),\n","        A.Rotate(limit=30, p=0.3),\n","        A.OneOf([\n","            A.Blur(blur_limit=3, p=0.3),\n","            A.GaussianBlur(blur_limit=3, p=0.3),\n","            A.MedianBlur(blur_limit=3, p=0.3)\n","        ], p=0.3),\n","        A.Normalize(),\n","        ToTensorV2()\n","    ]\n",")\n","\n","val_transform = A.Compose(\n","    [\n","        A.Resize(256, 256, interpolation=cv2.INTER_LINEAR),\n","        A.Normalize(),\n","        ToTensorV2()\n","    ]\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Train test split with ratio 0.8"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T14:34:09.129888Z","iopub.status.busy":"2023-11-15T14:34:09.129497Z","iopub.status.idle":"2023-11-15T14:34:09.137719Z","shell.execute_reply":"2023-11-15T14:34:09.136554Z","shell.execute_reply.started":"2023-11-15T14:34:09.129853Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Len of images: 900\n","Len of masks: 900\n","Len of images: 100\n","Len of masks: 100\n"]}],"source":["train_size = int(0.9 * len(img_list))\n","\n","train_dataset = NeolypsDataset(img_list[:train_size], mask_list[:train_size], transform=train_transform)\n","val_dataset = NeolypsDataset(img_list[train_size:], mask_list[train_size:], transform=val_transform)"]},{"cell_type":"markdown","metadata":{},"source":["Create the dataloader"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T14:34:09.140039Z","iopub.status.busy":"2023-11-15T14:34:09.139098Z","iopub.status.idle":"2023-11-15T14:34:09.151272Z","shell.execute_reply":"2023-11-15T14:34:09.150125Z","shell.execute_reply.started":"2023-11-15T14:34:09.139997Z"},"trusted":true},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Training Phase"]},{"cell_type":"markdown","metadata":{},"source":["Model"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T14:34:09.153578Z","iopub.status.busy":"2023-11-15T14:34:09.153145Z","iopub.status.idle":"2023-11-15T14:34:20.307790Z","shell.execute_reply":"2023-11-15T14:34:20.306852Z","shell.execute_reply.started":"2023-11-15T14:34:09.153545Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-5d3b4d8f.pth\n","100%|██████████| 170M/170M [00:03<00:00, 59.5MB/s] \n"]}],"source":["import segmentation_models_pytorch as smp\n","\n","model = smp.UnetPlusPlus(\n","    encoder_name=\"resnet101\",        \n","    encoder_weights=\"imagenet\",     \n","    in_channels=3,                  \n","    classes=3     \n",")\n","\n","model = model.to(device)\n","optimizer = optim.Adam(model.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T14:34:20.310795Z","iopub.status.busy":"2023-11-15T14:34:20.310422Z","iopub.status.idle":"2023-11-15T15:11:51.965591Z","shell.execute_reply":"2023-11-15T15:11:51.964360Z","shell.execute_reply.started":"2023-11-15T14:34:20.310763Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhokage321xxx\u001b[0m (\u001b[33mteam-thay-linh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.16.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.12"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20231115_143422-4ixb2b6x</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/team-thay-linh/DL-Assignment/runs/4ixb2b6x' target=\"_blank\">df-25-4-0.0001</a></strong> to <a href='https://wandb.ai/team-thay-linh/DL-Assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/team-thay-linh/DL-Assignment' target=\"_blank\">https://wandb.ai/team-thay-linh/DL-Assignment</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/team-thay-linh/DL-Assignment/runs/4ixb2b6x' target=\"_blank\">https://wandb.ai/team-thay-linh/DL-Assignment/runs/4ixb2b6x</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch [1/25], Step [50/225], Train Loss: 1.1319543850\n","Epoch [1/25], Step [100/225], Train Loss: 0.7186480618\n","Epoch [1/25], Step [150/225], Train Loss: 0.5158603072\n","Epoch [1/25], Step [200/225], Train Loss: 0.3988515103\n","Epoch [1/25], Validation Loss: 0.3332599866\n","Epoch [2/25], Step [50/225], Train Loss: 0.4446695375\n","Epoch [2/25], Step [100/225], Train Loss: 0.2226086900\n","Epoch [2/25], Step [150/225], Train Loss: 0.1968192291\n","Epoch [2/25], Step [200/225], Train Loss: 0.1599321449\n","Epoch [2/25], Validation Loss: 0.1506938908\n","Epoch [3/25], Step [50/225], Train Loss: 0.2192456159\n","Epoch [3/25], Step [100/225], Train Loss: 0.1196816754\n","Epoch [3/25], Step [150/225], Train Loss: 0.1110044847\n","Epoch [3/25], Step [200/225], Train Loss: 0.1107532476\n","Epoch [3/25], Validation Loss: 0.0933665892\n","Epoch [4/25], Step [50/225], Train Loss: 0.1563262979\n","Epoch [4/25], Step [100/225], Train Loss: 0.0863447028\n","Epoch [4/25], Step [150/225], Train Loss: 0.0735618801\n","Epoch [4/25], Step [200/225], Train Loss: 0.0771014240\n","Epoch [4/25], Validation Loss: 0.0800670926\n","Epoch [5/25], Step [50/225], Train Loss: 0.1027771430\n","Epoch [5/25], Step [100/225], Train Loss: 0.0670342767\n","Epoch [5/25], Step [150/225], Train Loss: 0.0803824381\n","Epoch [5/25], Step [200/225], Train Loss: 0.0836009406\n","Epoch [5/25], Validation Loss: 0.0723605250\n","Epoch [6/25], Step [50/225], Train Loss: 0.1014927161\n","Epoch [6/25], Step [100/225], Train Loss: 0.0665757042\n","Epoch [6/25], Step [150/225], Train Loss: 0.0574454227\n","Epoch [6/25], Step [200/225], Train Loss: 0.0548667029\n","Epoch [6/25], Validation Loss: 0.0742035305\n","Epoch [7/25], Step [50/225], Train Loss: 0.0995712454\n","Epoch [7/25], Step [100/225], Train Loss: 0.0687070597\n","Epoch [7/25], Step [150/225], Train Loss: 0.0436963790\n","Epoch [7/25], Step [200/225], Train Loss: 0.0475381708\n","Epoch [7/25], Validation Loss: 0.0604034887\n","Epoch [8/25], Step [50/225], Train Loss: 0.0789943757\n","Epoch [8/25], Step [100/225], Train Loss: 0.0566137258\n","Epoch [8/25], Step [150/225], Train Loss: 0.0627221145\n","Epoch [8/25], Step [200/225], Train Loss: 0.0617200195\n","Epoch [8/25], Validation Loss: 0.0671272513\n","Epoch [9/25], Step [50/225], Train Loss: 0.0900951447\n","Epoch [9/25], Step [100/225], Train Loss: 0.0480405099\n","Epoch [9/25], Step [150/225], Train Loss: 0.0486552843\n","Epoch [9/25], Step [200/225], Train Loss: 0.0388498746\n","Epoch [9/25], Validation Loss: 0.0548756804\n","Epoch [10/25], Step [50/225], Train Loss: 0.0705021009\n","Epoch [10/25], Step [100/225], Train Loss: 0.0461495611\n","Epoch [10/25], Step [150/225], Train Loss: 0.0396448715\n","Epoch [10/25], Step [200/225], Train Loss: 0.0456389209\n","Epoch [10/25], Validation Loss: 0.0757288313\n","Epoch [11/25], Step [50/225], Train Loss: 0.0745851423\n","Epoch [11/25], Step [100/225], Train Loss: 0.0379526583\n","Epoch [11/25], Step [150/225], Train Loss: 0.0599447102\n","Epoch [11/25], Step [200/225], Train Loss: 0.0364731920\n","Epoch [11/25], Validation Loss: 0.0510420488\n","Epoch [12/25], Step [50/225], Train Loss: 0.0654388398\n","Epoch [12/25], Step [100/225], Train Loss: 0.0404631241\n","Epoch [12/25], Step [150/225], Train Loss: 0.0355847205\n","Epoch [12/25], Step [200/225], Train Loss: 0.0545598795\n","Epoch [12/25], Validation Loss: 0.0538783716\n","Epoch [13/25], Step [50/225], Train Loss: 0.0515928567\n","Epoch [13/25], Step [100/225], Train Loss: 0.0532679115\n","Epoch [13/25], Step [150/225], Train Loss: 0.0501709546\n","Epoch [13/25], Step [200/225], Train Loss: 0.0417088814\n","Epoch [13/25], Validation Loss: 0.0521250925\n","Epoch [14/25], Step [50/225], Train Loss: 0.0464540581\n","Epoch [14/25], Step [100/225], Train Loss: 0.0309948169\n","Epoch [14/25], Step [150/225], Train Loss: 0.0311891718\n","Epoch [14/25], Step [200/225], Train Loss: 0.0505468774\n","Epoch [14/25], Validation Loss: 0.0494826534\n","Epoch [15/25], Step [50/225], Train Loss: 0.0579576744\n","Epoch [15/25], Step [100/225], Train Loss: 0.0273366916\n","Epoch [15/25], Step [150/225], Train Loss: 0.0283658508\n","Epoch [15/25], Step [200/225], Train Loss: 0.0354972690\n","Epoch [15/25], Validation Loss: 0.0586750238\n","Epoch [16/25], Step [50/225], Train Loss: 0.0520798092\n","Epoch [16/25], Step [100/225], Train Loss: 0.0389438673\n","Epoch [16/25], Step [150/225], Train Loss: 0.0337200344\n","Epoch [16/25], Step [200/225], Train Loss: 0.0302706193\n","Epoch [16/25], Validation Loss: 0.0588183486\n","Epoch [17/25], Step [50/225], Train Loss: 0.0669993663\n","Epoch [17/25], Step [100/225], Train Loss: 0.0327492279\n","Epoch [17/25], Step [150/225], Train Loss: 0.0285538741\n","Epoch [17/25], Step [200/225], Train Loss: 0.0376885150\n","Epoch [17/25], Validation Loss: 0.0508612759\n","Epoch [18/25], Step [50/225], Train Loss: 0.0486058662\n","Epoch [18/25], Step [100/225], Train Loss: 0.0456625478\n","Epoch [18/25], Step [150/225], Train Loss: 0.0330270926\n","Epoch [18/25], Step [200/225], Train Loss: 0.0261381933\n","Epoch [18/25], Validation Loss: 0.0566081698\n","Epoch [19/25], Step [50/225], Train Loss: 0.0571257950\n","Epoch [19/25], Step [100/225], Train Loss: 0.0315632071\n","Epoch [19/25], Step [150/225], Train Loss: 0.0304884215\n","Epoch [19/25], Step [200/225], Train Loss: 0.0358495090\n","Epoch [19/25], Validation Loss: 0.0580531660\n","Epoch [20/25], Step [50/225], Train Loss: 0.0383697211\n","Epoch [20/25], Step [100/225], Train Loss: 0.0296500888\n","Epoch [20/25], Step [150/225], Train Loss: 0.0416075529\n","Epoch [20/25], Step [200/225], Train Loss: 0.0281824877\n","Epoch [20/25], Validation Loss: 0.0509909772\n","Epoch [21/25], Step [50/225], Train Loss: 0.0553042386\n","Epoch [21/25], Step [100/225], Train Loss: 0.0261480336\n","Epoch [21/25], Step [150/225], Train Loss: 0.0247902341\n","Epoch [21/25], Step [200/225], Train Loss: 0.0259553208\n","Epoch [21/25], Validation Loss: 0.0625162904\n","Epoch [22/25], Step [50/225], Train Loss: 0.0552851572\n","Epoch [22/25], Step [100/225], Train Loss: 0.0582778227\n","Epoch [22/25], Step [150/225], Train Loss: 0.0512063360\n","Epoch [22/25], Step [200/225], Train Loss: 0.0326008654\n","Epoch [22/25], Validation Loss: 0.0534634364\n","Epoch [23/25], Step [50/225], Train Loss: 0.0405470451\n","Epoch [23/25], Step [100/225], Train Loss: 0.0271405087\n","Epoch [23/25], Step [150/225], Train Loss: 0.0369616126\n","Epoch [23/25], Step [200/225], Train Loss: 0.0406118196\n","Epoch [23/25], Validation Loss: 0.0588897836\n","Epoch [24/25], Step [50/225], Train Loss: 0.0547232417\n","Epoch [24/25], Step [100/225], Train Loss: 0.0256520820\n","Epoch [24/25], Step [150/225], Train Loss: 0.0542965692\n","Epoch [24/25], Step [200/225], Train Loss: 0.0377547097\n","Epoch [24/25], Validation Loss: 0.0552831464\n","Epoch [25/25], Step [50/225], Train Loss: 0.0407479142\n","Epoch [25/25], Step [100/225], Train Loss: 0.0236372163\n","Epoch [25/25], Step [150/225], Train Loss: 0.0290192305\n","Epoch [25/25], Step [200/225], Train Loss: 0.0358759682\n","Epoch [25/25], Validation Loss: 0.0562641467\n"]}],"source":["import wandb\n","\n","wandb.login(key=\"8b9a21f3b6f5fbf21131e5a7c7d5bf22a2ad5f0c\")\n","\n","wandb.init(project=\"DL-Assignment\", name=f'df-{num_epochs}-{batch_size}-{lr}')\n","\n","# Training loop\n","train_loss = 0\n","best_val_loss = float('inf')\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    \n","    for i, (img, label) in enumerate(train_dataloader):\n","        img = img.to(device)\n","        label = label.to(device)\n","        \n","        # Forward \n","        label = label.squeeze(dim=1).long()\n","        outputs = model(img)\n","        \n","        # Loss \n","        loss = criterion(outputs, label)\n","        \n","        # Backward\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        \n","        train_loss += loss.item()\n","        \n","        if (i + 1) % display_step == 0:\n","            avg_train_loss = train_loss / display_step\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_dataloader)}], Train Loss: {avg_train_loss:.10f}\")\n","            wandb.log({\"Train loss\": avg_train_loss})\n","            train_loss = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","        val_loss = 0\n","        \n","        for img, label in val_dataloader:\n","            img = img.to(device)\n","            label = label.to(device)\n","            \n","            label = label.squeeze(dim=1).long()\n","            outputs = model(img)\n","            \n","            val_loss += criterion(outputs.float(), label.long()).item()\n","    \n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss/len(val_dataloader):.10f}\")\n","    \n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        checkpoint = {\n","            'epoch': epoch,\n","            'model': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'loss': val_loss,\n","        }\n","        torch.save(checkpoint, 'model.pth')\n","    \n","    wandb.log({\"Valid loss\": val_loss})"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":3984786,"sourceId":6938815,"sourceType":"datasetVersion"}],"dockerImageVersionId":30579,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
